{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijGzTHJJUCPY"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDsTUvKjwHBW"
      },
      "source": [
        "# RAG 基本實作\n",
        "<table>\n",
        "<td style=\"text-align: center\">\n",
        "  <a href=\"https://colab.research.google.com/github/TWCkaijin/GDGC-Gemini-bootcamp/blob/main/RAG/Vertex%20AI%20RAG%20Search%20Workshop.ipynb\">\n",
        "    <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "  </a>\n",
        "</td>        \n",
        "<td style=\"text-align: center\">\n",
        "  <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FTWCkaijin%2FGDGC-Gemini-bootcamp%2Frefs%2Fheads%2Fmain%2FRAG%2FVertex%20AI%20RAG%20Search%20Workshop.ipynb\">\n",
        "    <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "  </a>\n",
        "</td>\n",
        "\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsjCZ1v9rP7s"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|原作者 | [Lavi Nigam](https://github.com/lavinigam-gcp) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0KqoJXJHzkT"
      },
      "source": [
        "DIY version of RAG [**building_DIY_multimodal_qa_system_with_mRAG.ipynb**](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/qa-ops/building_DIY_multimodal_qa_system_with_mRAG.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK1Q5ZYdVL4Y"
      },
      "source": [
        "## 概述\n",
        "檢索增強生成（Retrieval Augmented Generation, RAG）已成為讓大型語言模型（LLMs）存取外部數據的重要範式，同時也作為一種機制，能有效減少幻覺現象（hallucinations）。\n",
        "\n",
        "在此筆記本中，您將學習如何進行多模態 RAG，透過結合文字與圖片的財務文件進行問答。\n",
        "\n",
        "## Gemini\n",
        "- Gemini 是 Google DeepMind 開發的一系列生成式 AI 模型，專為多模態應用設計。\n",
        "- Gemini API 提供對 Gemini 3.0 Pro 、Gemini 2.5 Pro 和 Gemini 2.5 Flash 模型的存取。\n",
        "\n",
        "## 比較文字型與多模態 RAG\n",
        "多模態 RAG 相較於文字型 RAG 具有以下幾項優勢：\n",
        "\n",
        "1. 增強的知識存取能力：\n",
        "多模態 RAG 能處理文字與視覺資訊，為大型語言模型提供更豐富、更全面的知識基礎。\n",
        "\n",
        "2. 改進的推理能力：\n",
        "藉由整合視覺線索，多模態 RAG 能在不同數據模態之間進行更明智的推斷。\n",
        "\n",
        "此筆記本將教您如何在 Vertex AI 中，結合 Gemini API、文字嵌入 和 多模態嵌入，構建文件搜尋引擎。\n",
        "\n",
        "透過實際操作範例，您將學會如何為文件來源建構一個多媒體豐富的中繼資料庫，實現跨多元資訊流的搜尋、比較與推理功能。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQT500QqVPIb"
      },
      "source": [
        "## 單元目標\n",
        "本筆記本逐步提供建構文件搜尋引擎的指南，透過多模態檢索增強生成（RAG）實現以下功能：\n",
        "\n",
        "- 提取並儲存包含文字的文件中繼資料(metadata)，並為文件生成嵌入向量\n",
        "- 使用文字查詢搜尋中繼資料(metadata)，並向LLM提供檢索結果並回答問題"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnpYxfesh2rI"
      },
      "source": [
        "## 工具:\n",
        "請注意，專案必須要啟動以下GCP API服務:\n",
        "- Vertex AI API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXJpXzKrh2rJ"
      },
      "source": [
        "## 基本設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5afkyDMSBW5"
      },
      "source": [
        "### 下載安裝 Vertex AI SDK for Python 及其他相依套件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kc4WxYmLSBW5",
        "outputId": "ced9494a-bd24-4097-bacd-78ed6c556b94"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --user google-cloud-aiplatform pymupdf rich colorama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### 重啟以確保套件成功載入"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRvKdaPDTznN",
        "outputId": "f9688ae8-3c02-4151-e9b2-72e396d79b09"
      },
      "outputs": [],
      "source": [
        "# Restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtsU9Bw9h2rL"
      },
      "source": [
        "### 驗證Colab 環境(僅Colab需要)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpYEyLsOh2rL"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1vKZZoEh2rL"
      },
      "source": [
        "### 初始化 GCP 專案設定\n",
        "請注意，專案必須要啟動以下API服務:\n",
        "- Vertex AI API\n",
        "\n",
        "https://console.cloud.google.com</br>\n",
        "\n",
        "以下輸入您的專案ID以及欲使用的伺服器區域。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJqZ76rJh2rM",
        "outputId": "99cf4f3d-60b2-4a68-94ff-432bfab19742"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "PROJECT_ID = \"[YOUR-PROJECT-ID]\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "# if not running on Colab, try to get the PROJECT_ID automatically\n",
        "if \"google.colab\" not in sys.modules:\n",
        "    import subprocess\n",
        "\n",
        "    PROJECT_ID = subprocess.check_output(\n",
        "        [\"gcloud\", \"config\", \"get-value\", \"project\"], text=True\n",
        "    ).strip()\n",
        "\n",
        "print(f\"Your project ID is: {PROJECT_ID}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umWOVxrBdRR6"
      },
      "source": [
        "### 初始化 Vertex AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D48gUW5-h2rM"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Initialize Vertex AI\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuQwwRiniVFG"
      },
      "source": [
        "### 導入函式庫"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtMowvm-yQ97"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display\n",
        "from rich.markdown import Markdown as rich_Markdown\n",
        "from vertexai.generative_models import GenerationConfig, GenerativeModel, Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-TX_R_xh2rM"
      },
      "source": [
        "### 定義及載入 Gemini 2.5 Pro 和 Gemini 2.5 Flash 模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvMwSRJJh2rM"
      },
      "outputs": [],
      "source": [
        "text_model = GenerativeModel(\"gemini-2.5-flash\")\n",
        "multimodal_model = GenerativeModel(\"gemini-2.5-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lCfREXK5SWD"
      },
      "source": [
        "### 下載示範用檔案以及額外套件\n",
        "\n",
        "For original code: (`intro_multimodal_rag_utils.py`) directly on [GitHub](https://storage.googleapis.com/github-repo/rag/intro_multimodal_rag/intro_multimodal_rag_old_version/intro_multimodal_rag_utils.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwbL89zcY39N",
        "outputId": "4e21d792-c9af-4555-b5cd-136dcbdef63c"
      },
      "outputs": [],
      "source": [
        "# download documents and images used in this notebook\n",
        "!gsutil -m rsync -r gs://github-repo/rag/intro_multimodal_rag/intro_multimodal_rag_old_version .\n",
        "!mkdir pdf\n",
        "!curl -o ./pdf/example.pdf https://raw.githubusercontent.com/TWCkaijin/GDGC-Gemini-bootcamp/main/RAG/Korvin%20Fantasy.pdf\n",
        "print(\"Download completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps1G-cCfpibN"
      },
      "source": [
        "## 1. 建立包含文字metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqLsy3iZ5t-R"
      },
      "source": [
        "### 範例資料內容\n",
        "\n",
        "在此筆記本中，我們將使用的原始數據為一篇「虛構角色的生平故事」\n",
        "\n",
        "單一、獨立且無出現在網路上的內容，適合進行多模態檢索增強生成（RAG）的實驗與學習。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvt0sus5KSNX"
      },
      "source": [
        "\n",
        "### 匯入輔助函數以建立metadata\n",
        "在構建多模態 RAG 系統之前，需先準備文件中所有文字與圖片的metadata。為了便於引用與參考，metadata應包含關鍵元素，例如頁碼、檔案名稱等。\n",
        "\n",
        "接下來，您將從這些metadata中生成嵌入向量，這些嵌入向量是執行相似性搜尋時的必要條件。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3wo2jv2rP7v"
      },
      "outputs": [],
      "source": [
        "from intro_multimodal_rag_utils import get_document_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BOAkYN0KlSL"
      },
      "source": [
        "### 從文件中提取並儲存文字和圖片的metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9hBPPWs5CMd"
      },
      "source": [
        "我們剛剛匯入了一個名為 ```get_document_metadata()``` 的函數。這個函數會從文件中提取文字和圖片的中繼資料，並返回兩個資料框，分別為 ```text_metadata``` 和 ```image_metadata``` 。如果你想了解更多有關 ```get_document_metadata()``` 函數如何使用 Gemini 和嵌入模型實現的細節，你可以直接查看[source code](https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/use-cases/retrieval-augmented-generation/utils/intro_multimodal_rag_utils.py)。\n",
        "\n",
        "提取並儲存文字和圖片metadata的原因在於，僅使用其中一個資料類型不足以得出相關的答案。例如，相關答案可能以視覺形式存在於文件中，但文字型 RAG 無法考慮到視覺圖像。你稍後會在這本筆記本中探索這個範例。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnKru0sBh2rN"
      },
      "source": [
        "在下一步，我們將使用這個函數來提取並儲存文件中文字和圖片的metadata。請注意，以下的程式區塊可能需要幾分鐘才能完成執行。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFgRwzokrP7v"
      },
      "source": [
        "注意事項：\n",
        "\n",
        "目前的實現最適用於以下情況：\n",
        "\n",
        "* 文件中包含文字和圖片的組合。\n",
        "* 文件中的表格以圖片形式呈現。\n",
        "* 文件中的圖片不需要太多上下文信息。</br>\n",
        "\n",
        "另外，\n",
        "* 你也可以使用常規的 RAG 方法。可以參考這份檔案 [RAG_text_only](https://github.com/kevin6449/LANGCHAIN_RAG/blob/main/LangChain_RAG.ipynb)\n",
        "* 如果文件包含額外特定領域的知識，可以將這些信息傳遞至下方的提示語中。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nflT_j-9QzC_"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ 不要傳送超過50頁的資料，你可能會遇到流量限制 ⚠️</b></br>\n",
        "⚠️ 如果你遇到了其他形式的流量限制，請開啟下方的add_sleep_after_page並設定sleep_time_after_page ⚠️\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8hE0tWD-lf8",
        "outputId": "e335c507-9685-4c7d-f44e-3fff02baa089"
      },
      "outputs": [],
      "source": [
        "pdf_folder_path = \"pdf/\"\n",
        "\n",
        "\n",
        "image_description_prompt = \"\"\"\n",
        "Explain what is going on in the image.\n",
        "please describe the whole plot according to the image\n",
        "\"\"\"\n",
        "\n",
        "# Extract text and image metadata from the PDF document\n",
        "text_metadata_df, image_metadata_df = get_document_metadata(\n",
        "    multimodal_model, \n",
        "    pdf_folder_path,\n",
        "    image_save_dir=\"images\",\n",
        "    image_description_prompt=image_description_prompt,\n",
        "    embedding_size=1408,\n",
        "    add_sleep_after_page = True,\n",
        "    sleep_time_after_page = 11, \n",
        ")\n",
        "\n",
        "print(\"\\n\\n --- Completed processing. ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miBBoEXwh2rN"
      },
      "source": [
        "#### 檢視處理過的文字metadata\n",
        "以下的程式區塊將產生一個metadata表格，描述不同部分的文字metadata，包括：\n",
        "\n",
        "- text: 來自頁面的原始文字\n",
        "- text_embedding_page: 頁面上原始文字的嵌入向量\n",
        "- chunk_text: 將原始文字分割成較小的區塊\n",
        "- chunk_number: 每個文字區塊的索引\n",
        "- text_embedding_chunk: 每個文字區塊的嵌入向量\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "collapsed": true,
        "id": "6t3AIGFar8Mo",
        "outputId": "1101cf2d-02ba-4377-c8a7-5b6d3b79b9bb"
      },
      "outputs": [],
      "source": [
        "text_metadata_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBhoOkutUtPr"
      },
      "source": [
        "### 匯入輔助函數以實現 RAG\n",
        "你將匯入以下函數，這些函數將在本筆記本的其餘部分中用來實現 RAG：\n",
        "\n",
        "- ```get_similar_text_from_query()```：根據文字查詢，使用餘弦相似度算法從文件中找出相關的文字。此函數使用中繼資料中的文字嵌入向量來計算結果，並可以根據最高分數、頁碼/區塊號或嵌入向量大小來過濾結果。\n",
        "- ```print_text_to_text_citation()```：印出從 ```get_similar_text_from_query()``` 函數檢索到的文字來源（引用）和細節。\n",
        "- ```get_similar_image_from_query()```：根據圖片路徑或圖片，從文件中找出相關的圖片。此函數使用中繼資料中的圖片嵌入向量。\n",
        "- ```print_text_to_image_citation()```：印出從 ```get_similar_image_from_query()``` 函數檢索到的圖片來源（引用）和細節。\n",
        "- ```get_gemini_response()```：與 Gemini 模型互動，基於文字和圖片輸入的結合來回答問題。\n",
        "- ```display_images()```：顯示一系列圖片，這些圖片可以是路徑或 PIL 圖片對象。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tngn_vrIKdE1"
      },
      "outputs": [],
      "source": [
        "from intro_multimodal_rag_utils import (\n",
        "    display_images,\n",
        "    get_gemini_response,\n",
        "    get_similar_image_from_query,\n",
        "    get_similar_text_from_query,\n",
        "    print_text_to_image_citation,\n",
        "    print_text_to_text_citation,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHuLlEvSKFWt"
      },
      "source": [
        "## 2. 文字搜尋\n",
        "讓我們從一個簡單的問題開始，看看使用文字嵌入向量的簡單文字搜尋是否能夠回答這個問題。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mrFVhtCut7t"
      },
      "outputs": [],
      "source": [
        "query = \"what is this file mainly about\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWw7-AIar-S8"
      },
      "source": [
        "### 使用文字搜尋來尋找相關資料"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEzP6Yyv7N-G",
        "outputId": "9e6a106f-3598-49d9-bb41-921666a4089b"
      },
      "outputs": [],
      "source": [
        "# Matching user text query with \"chunk_embedding\" to find relevant chunks.\n",
        "matching_results_text = get_similar_text_from_query(\n",
        "    query,\n",
        "    text_metadata_df,\n",
        "    column_name=\"text_embedding_chunk\",\n",
        "    top_n=7,\n",
        "    chunk_text=True,\n",
        ")\n",
        "\n",
        "# Print the matched text citations\n",
        "print_text_to_text_citation(matching_results_text, print_top=False, chunk_text=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0bnOOf2rP70"
      },
      "source": [
        "我們可以發現，第一個高分結果包含了我們需要的信息，但仔細檢查後發現，它提到該信息存在於“以下”表格中。該表格數據是以圖片形式存在，而非文字，因此除非能處理圖片及其數據，否則很可能會錯過這些信息。\n",
        "\n",
        "不過，讓我們將相關的文字區塊輸入 Gemini 1.0 Pro 模型，看看它是否能在考慮文件中所有區塊的情況下給出我們想要的答案。這就像是基本的文字型 RAG 實現。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQREZrGsXmPc",
        "outputId": "8cccf54a-7b07-41e8-f007-05d03bcd27a8"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"\\n **** Result: ***** \\n\")\n",
        "\n",
        "# All relevant text chunk found across documents based on user query\n",
        "context = \"\\n\".join(\n",
        "    [value[\"chunk_text\"] for key, value in matching_results_text.items()]\n",
        ")\n",
        "\n",
        "instruction = f\"\"\"Answer the question with the given context.\n",
        "If the information is not available in the context, return \"not available in the context\" and explain the situation.\n",
        "Question: {query}\n",
        "Context: {context}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "model_input = instruction\n",
        "\n",
        "# Generate Gemini response with streaming output\n",
        "Markdown(get_gemini_response(\n",
        "    text_model, \n",
        "    model_input=model_input,\n",
        "    stream=True,\n",
        "    generation_config=GenerationConfig(temperature=0.2),\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4oxQO3bfKEs"
      },
      "source": [
        "#### 接下來，讓我們來問問更多關於主角的故事吧~~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "o-GbnrEgXmr6"
      },
      "outputs": [],
      "source": [
        "while(True):\n",
        "  query = input()\n",
        "\n",
        "  # Matching user text query with \"chunk_embedding\" to find relevant chunks.\n",
        "  matching_results_text = get_similar_text_from_query(\n",
        "      query,\n",
        "      text_metadata_df,\n",
        "      column_name=\"text_embedding_chunk\",\n",
        "      top_n=7,\n",
        "      chunk_text=True,\n",
        "  )\n",
        "\n",
        "  # Print the matched text citations\n",
        "  #print_text_to_text_citation(matching_results_text, print_top=False, chunk_text=True)\n",
        "\n",
        "\n",
        "  print(\"\\n **** Result: ***** \\n\")\n",
        "\n",
        "  # All relevant text chunk found across documents based on user query\n",
        "  context = \"\\n\".join(\n",
        "      [value[\"chunk_text\"] for key, value in matching_results_text.items()]\n",
        "  )\n",
        "\n",
        "  instruction = f\"\"\"Answer the question with the given context.\n",
        "  If the information is not available in the context, return \"not available in the context\" and explain the situation.\n",
        "  Question: {query}\n",
        "  Context: {context}\n",
        "  Answer:\n",
        "  \"\"\"\n",
        "\n",
        "  # Prepare the model input\n",
        "  model_input = instruction\n",
        "\n",
        "  # Generate Gemini response with streaming output\n",
        "  print(get_gemini_response(\n",
        "      text_model,  # we are passing Gemini 1.0 Pro\n",
        "      model_input=model_input,\n",
        "      stream=True,\n",
        "      generation_config=GenerationConfig(temperature=0.2),\n",
        "  ))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 使用文字來做圖像搜索"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "我們一樣先建立一個Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"How is the final battle looks?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "接下來，使用已經寫好的工具函式`get_similar_image_from_query`，他會回傳相近的圖片以及圖片的描述資料。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "matching_results_image = get_similar_image_from_query(\n",
        "    text_metadata_df,\n",
        "    image_metadata_df,\n",
        "    query=query,\n",
        "    column_name=\"text_embedding_from_image_description\",  # Use image description text embedding\n",
        "    image_emb=False,  # Use text embedding instead of image embedding\n",
        "    top_n=3,\n",
        "    embedding_size=1408,\n",
        ")\n",
        "\n",
        "print(\"\\n **** Result: ***** \\n\")\n",
        "\n",
        "# Display the top matching image\n",
        "display(matching_results_image[0][\"image_object\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "接下來，建立整合的Prompt，並傳送給Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n **** Result: ***** \\n\")\n",
        "\n",
        "# All relevant text chunk found across documents based on user query\n",
        "context = f\"\"\"Image: {matching_results_image[0]['image_object']}\n",
        "Description: {matching_results_image[0]['image_description']}\n",
        "\"\"\"\n",
        "\n",
        "instruction = f\"\"\"Answer the question in JSON format with the given context of Image and its Description. Only include value.\n",
        "Question: {query}\n",
        "Context: {context}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "model_input = instruction\n",
        "\n",
        "Markdown(\n",
        "    get_gemini_response(\n",
        "        multimodal_model_flash, \n",
        "        model_input=model_input,\n",
        "        stream=True,\n",
        "        generation_config=GenerationConfig(temperature=1),\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "使用`print_text_to_image_citation`可以取得資料的出處"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Markdown(print_text_to_image_citation(matching_results_image, print_top=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "使用圖片來查詢圖片"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# You can find a similar image as per the images you have in the metadata.\n",
        "# In this case, you have a table (picked from the same document source) and you would like to find similar tables in the document.\n",
        "image_query_path = \"tac_table_revenue.png\"\n",
        "\n",
        "# Print a message indicating the input image\n",
        "print(\"***Input image from user:***\")\n",
        "\n",
        "# Display the input image\n",
        "Image.load_from_file(image_query_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "接下來使用Image embedder 來嵌入圖片。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Search for Similar Images Based on Input Image and Image Embedding\n",
        "\n",
        "matching_results_image = get_similar_image_from_query(\n",
        "    text_metadata_df,\n",
        "    image_metadata_df,\n",
        "    query=query,  # Use query text for additional filtering (optional)\n",
        "    column_name=\"mm_embedding_from_img_only\",  # Use image embedding for similarity calculation\n",
        "    image_emb=True,\n",
        "    image_query_path=image_query_path,  # Use input image for similarity calculation\n",
        "    top_n=3,  # Retrieve top 3 matching images\n",
        "    embedding_size=1408,  # Use embedding size of 1408\n",
        ")\n",
        "\n",
        "print(\"\\n **** Result: ***** \\n\")\n",
        "\n",
        "# Display the Top Matching Image\n",
        "display(\n",
        "    matching_results_image[0][\"image_object\"]\n",
        ")  # Display the top matching image object (Pillow Image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "印出圖片出處"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display citation details for the top matching image\n",
        "print_text_to_image_citation(\n",
        "    matching_results_image, print_top=True\n",
        ")  # Print citation details for the top matching image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "列印出結果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check Other Matched Images (Optional)\n",
        "# You can access the other two matched images using:\n",
        "\n",
        "print(\"---------------Matched Images------------------\\n\")\n",
        "display_images(\n",
        "    [\n",
        "        matching_results_image[0][\"img_path\"],\n",
        "        matching_results_image[1][\"img_path\"],\n",
        "    ],\n",
        "    resize_ratio=0.5,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
